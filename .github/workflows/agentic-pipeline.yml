# Vibe Data Platform - Agentic Pipeline Workflow
#
# This workflow gives Claude full developer control over the pipeline.
# Claude acts as an autonomous developer who can:
#   - Run dbt commands
#   - Diagnose and fix errors
#   - Commit fixes to the repository
#   - Create GitHub Issues for unresolvable problems
#   - Retry until success or max attempts reached
#
# Required GitHub Secrets:
#   CLAUDE_CODE_OAUTH_TOKEN   - OAuth token for Claude Code Action
#   AZURE_STORAGE_ACCOUNT     - Azure Storage account name
#   AZURE_STORAGE_KEY         - Azure Storage account access key
#   LOGIC_APP_EMAIL_URL       - Logic App HTTP trigger URL (optional)
#   NOTIFICATION_WEBHOOK_URL  - Teams or Slack webhook URL (optional)

name: Agentic Data Pipeline

permissions:
  contents: write       # Commit fixes directly
  pull-requests: write  # Create PRs if preferred
  issues: write         # Create issues for unresolvable failures
  id-token: write       # Required for claude-code-action and GitHub Pages
  pages: write          # Deploy dashboard to GitHub Pages

on:
  schedule:
    - cron: '0 6 * * *'  # Daily at 6:00 AM UTC

  workflow_dispatch:
    inputs:
      dbt_command:
        description: 'dbt command to run'
        required: false
        default: 'build'
        type: choice
        options:
          - build
          - run
          - test
          - seed
      dbt_select:
        description: 'Model selection (optional)'
        required: false
        default: ''
      full_refresh:
        description: 'Run with --full-refresh'
        required: false
        default: false
        type: boolean
      max_retries:
        description: 'Max retry attempts for self-healing'
        required: false
        default: '3'
        type: choice
        options:
          - '1'
          - '2'
          - '3'
          - '5'

env:
  AZURE_STORAGE_ACCOUNT: ${{ secrets.AZURE_STORAGE_ACCOUNT }}
  AZURE_STORAGE_KEY: ${{ secrets.AZURE_STORAGE_KEY }}

jobs:
  # =============================================================================
  # Main Job: Claude acts as autonomous developer
  # =============================================================================
  agentic-pipeline:
    name: Claude Developer Agent
    runs-on: ubuntu-latest

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        with:
          token: ${{ secrets.GITHUB_TOKEN }}
          fetch-depth: 0  # Full history for proper git operations

      - name: Configure Git
        run: |
          git config user.name "Claude Agent"
          git config user.email "claude-agent@${{ github.repository_owner }}.github.io"

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'
          cache: 'pip'
          cache-dependency-path: 'requirements.txt'

      - name: Install Python dependencies
        run: |
          pip install -r requirements.txt

      - name: Set up Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '20'
          cache: 'npm'
          cache-dependency-path: dashboard/package-lock.json

      - name: Install dashboard dependencies
        working-directory: dashboard
        run: npm ci || npm install

      - name: Setup directories
        run: |
          mkdir -p data/processed data/raw logs

      - name: Download DuckDB from Azure
        run: |
          az storage blob download \
            --account-name $AZURE_STORAGE_ACCOUNT \
            --container-name duckdb \
            --name vibe.duckdb \
            --file data/processed/vibe.duckdb \
            --auth-mode key \
            --account-key $AZURE_STORAGE_KEY \
            2>/dev/null || echo "No existing database, starting fresh"

      - name: Download raw data from Azure
        run: |
          az storage blob download-batch \
            --account-name $AZURE_STORAGE_ACCOUNT \
            --source raw \
            --destination data/raw \
            --auth-mode key \
            --account-key $AZURE_STORAGE_KEY \
            2>/dev/null || echo "No raw data in Azure or download failed"

      # =========================================================================
      # Claude Developer Agent - Full autonomy to run, fix, commit, and report
      # =========================================================================
      - name: Claude Developer Agent
        id: claude
        uses: anthropics/claude-code-action@v1
        with:
          claude_code_oauth_token: ${{ secrets.CLAUDE_CODE_OAUTH_TOKEN }}

          prompt: |
            # You are a Developer on the Vibe Data Platform

            You have full autonomy to run the data pipeline, fix any issues, commit your changes, and report results. Act like an experienced data engineer.

            ## Your Mission

            1. **Extract fresh data from APIs** (weather, etc.)
            2. **Run the dbt pipeline** and ensure it succeeds
            3. **Export dashboard data** to Parquet files
            4. **Build the dashboard** using Observable Framework

            If anything fails, diagnose the problem, fix it, and retry. You have up to **${{ inputs.max_retries || '3' }} attempts**.

            ## Pipeline Commands

            **IMPORTANT:** Use subshells `(cd dir && command)` to avoid changing the working directory. All scripts expect to run from the repository root.

            ```bash
            # Step 1: Extract API data (from repo root)
            python scripts/extract_api.py

            # Step 2: Run dbt pipeline (subshell keeps us in repo root)
            (cd dbt && dbt ${{ inputs.dbt_command || 'build' }}${{ inputs.dbt_select && format(' --select {0}', inputs.dbt_select) || '' }}${{ inputs.full_refresh == 'true' && ' --full-refresh' || '' }})

            # Step 3: Export dashboard data (from repo root)
            python scripts/export_dashboard_data.py

            # Step 4: Build dashboard (subshell keeps us in repo root)
            (cd dashboard && npm run build)
            ```

            **Important:** The dashboard build is part of your mission. If it fails (TypeScript errors, missing data, etc.), diagnose and fix the issue just like you would for dbt errors.

            ## Agent Notes

            **IMPORTANT:** Before starting, read `.claude/agent-notes.md` for lessons learned from previous runs. This file contains important information about labels, common errors, and tips.

            If you learn something new (e.g., a label doesn't exist, a command fails in a specific way), **update the agent notes file** so future runs benefit from your experience.

            ## Your Capabilities

            You can do everything a developer would do:

            1. **Run commands** - Execute dbt, python scripts, npm, any CLI tools
            2. **Read and edit files** - Examine models, fix SQL, update configs, fix TypeScript/JS
            3. **Commit changes** - Use `git add`, `git commit`, `git push` to save fixes
            4. **Create GitHub Issues** - Use `gh issue create` for problems you can't solve
            5. **Use project skills** - `/diagnose`, `/apply-fix`, `/validate` are available
            6. **Update agent notes** - Add learnings to `.claude/agent-notes.md` for future runs

            ## Workflow

            1. **Extract API data** - Run `python scripts/extract_api.py` for fresh data
            2. **Run the dbt pipeline** - Execute the dbt command
            3. **Export dashboard data** - Run `python scripts/export_dashboard_data.py`
            4. **Build dashboard** - Run `cd dashboard && npm run build`
            5. **If all succeed** - Close any open tracking issue, report success, exit
            6. **If failure**:
               - **Create a GitHub Issue immediately** (before attempting fixes)
               - Analyze the error output
               - Use `/diagnose` to understand root cause
               - Fix the issue (edit SQL, configs, etc.)
               - Create a backup before modifying files
               - Commit your fix with a descriptive message
               - Retry the pipeline
               - If retry succeeds: **Close the issue** with fix details
               - If max attempts exhausted: **Update the issue** with RCA (don't create a new one)

            ## Issue Lifecycle Management

            **IMPORTANT:** Track pipeline failures with GitHub Issues throughout the self-healing process.

            ### On First Failure - Create Issue Immediately
            ```bash
            ISSUE_URL=$(gh issue create \
              --title "Pipeline Failure: <brief error summary>" \
              --label "bug,pipeline-failure,auto-healing" \
              --body "## üî¥ Pipeline Failure Detected

            **Run:** ${{ github.server_url }}/${{ github.repository }}/actions/runs/${{ github.run_id }}
            **Branch:** ${{ github.ref_name }}
            **Time:** $(date -u +%Y-%m-%dT%H:%M:%SZ)

            ## Error
            \`\`\`
            <error message>
            \`\`\`

            ## Status
            üîÑ **Auto-healing in progress...**

            ---
            *This issue was created automatically. It will be closed if the fix succeeds.*")
            ISSUE_NUMBER=$(echo $ISSUE_URL | grep -oE '[0-9]+$')
            echo "Created issue #$ISSUE_NUMBER"
            ```

            Store the issue number - you'll need it later.

            ### On Successful Fix - Close the Issue
            ```bash
            gh issue close $ISSUE_NUMBER --comment "## ‚úÖ Fixed Automatically

            **Fix applied:** <description of what you fixed>
            **Commit:** <commit SHA or link>
            **Attempt:** <which retry succeeded, e.g., 2 of 3>

            The pipeline is now passing."
            ```

            ### On All Retries Exhausted - Update (Don't Create New)
            ```bash
            gh issue comment $ISSUE_NUMBER --body "## ‚ùå Auto-healing Failed

            **Attempts exhausted:** ${{ inputs.max_retries || '3' }}

            ## Root Cause Analysis
            <your diagnosis>

            ## Attempted Fixes
            1. <fix 1 and why it didn't work>
            2. <fix 2 and why it didn't work>

            ## Recommended Manual Steps
            - <what a human should do>

            ## Relevant Files
            - <list files involved>

            ---
            *Manual intervention required.*"

            gh issue edit $ISSUE_NUMBER --add-label "needs-triage" --remove-label "auto-healing"
            ```

            ## Git Commit Guidelines

            When committing fixes:
            ```bash
            git add -A
            git commit -m "fix(dbt): <brief description>

            - Root cause: <what was wrong>
            - Fix applied: <what you changed>
            - Issue: #$ISSUE_NUMBER

            Co-Authored-By: Claude <noreply@anthropic.com>"
            git push origin ${{ github.ref_name }}
            ```

            ## Important Rules

            - **Create issue on first failure** - Always track failures with a GitHub Issue before fixing
            - **Close issue on success** - When the pipeline passes after a fix, close the tracking issue
            - **Be efficient** - Don't over-analyze, fix and move on
            - **Commit each fix** - Don't batch multiple unrelated fixes
            - **Preserve data** - Never delete production data
            - **Log everything** - Your output is the audit trail
            - **Confidence threshold** - Apply fixes you're >= 70% confident about

            ## Context

            - Repository: ${{ github.repository }}
            - Branch: ${{ github.ref_name }}
            - Trigger: ${{ github.event_name }}
            - Run ID: ${{ github.run_id }}

            Now, run the pipeline and handle whatever comes up. Good luck!

          additional_permissions: |
            Bash(dbt:*)
            Bash(cd:*)
            Bash(git:*)
            Bash(gh:*)
            Bash(pip:*)
            Bash(python:*)
            Bash(npm:*)
            Bash(cat:*)
            Bash(ls:*)
            Bash(mkdir:*)
            Bash(az:*)

          claude_args: |
            --max-turns 75
            --allowedTools "Bash,Edit,Read,Write,Glob,Grep,WebFetch,WebSearch,TodoWrite,Skill"

      # =========================================================================
      # Post-Agent: Deploy dashboard and upload data to Azure
      # =========================================================================
      - name: Upload dashboard artifact for Pages
        if: success()
        uses: actions/upload-pages-artifact@v3
        with:
          path: dashboard/dist

      - name: Upload dashboard data to Azure
        if: success()
        run: |
          # Create dashboard container if it doesn't exist
          az storage container create \
            --account-name $AZURE_STORAGE_ACCOUNT \
            --name dashboard \
            --auth-mode key \
            --account-key $AZURE_STORAGE_KEY \
            2>/dev/null || true

          # Upload parquet files for backup/other workflows
          for file in dashboard/src/data/*.parquet; do
            if [ -f "$file" ]; then
              FILENAME=$(basename "$file")
              echo "Uploading $FILENAME to Azure..."
              az storage blob upload \
                --account-name $AZURE_STORAGE_ACCOUNT \
                --container-name dashboard \
                --name "$FILENAME" \
                --file "$file" \
                --overwrite \
                --auth-mode key \
                --account-key $AZURE_STORAGE_KEY
            fi
          done
          echo "Dashboard data uploaded to Azure"

      - name: Upload DuckDB to Azure
        if: always()
        run: |
          if [ -f "data/processed/vibe.duckdb" ]; then
            az storage blob upload \
              --account-name $AZURE_STORAGE_ACCOUNT \
              --container-name duckdb \
              --name vibe.duckdb \
              --file data/processed/vibe.duckdb \
              --overwrite \
              --auth-mode key \
              --account-key $AZURE_STORAGE_KEY
            echo "DuckDB uploaded to Azure"
          fi

      - name: Upload raw data to Azure
        if: always()
        run: |
          if [ -d "data/raw" ] && [ "$(ls -A data/raw 2>/dev/null)" ]; then
            az storage blob upload-batch \
              --account-name $AZURE_STORAGE_ACCOUNT \
              --destination raw \
              --source data/raw \
              --overwrite \
              --auth-mode key \
              --account-key $AZURE_STORAGE_KEY
            echo "Raw data uploaded to Azure"
          fi

      - name: Upload logs to Azure
        if: always()
        run: |
          TIMESTAMP=$(date +%Y%m%d_%H%M%S)
          for logfile in logs/*.log; do
            if [ -f "$logfile" ]; then
              BASENAME=$(basename "$logfile" .log)
              az storage blob upload \
                --account-name $AZURE_STORAGE_ACCOUNT \
                --container-name logs \
                --name "${BASENAME}_${TIMESTAMP}.log" \
                --file "$logfile" \
                --auth-mode key \
                --account-key $AZURE_STORAGE_KEY 2>/dev/null || true
            fi
          done

      - name: Upload artifacts
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: pipeline-results
          path: |
            logs/
            data/processed/*.duckdb
          retention-days: 30

      # =========================================================================
      # Notifications
      # =========================================================================
      - name: Notify Success
        if: success()
        run: |
          if [ -n "${{ secrets.NOTIFICATION_WEBHOOK_URL }}" ]; then
            curl -X POST "${{ secrets.NOTIFICATION_WEBHOOK_URL }}" \
              -H "Content-Type: application/json" \
              -d '{
                "text": "‚úÖ Vibe Pipeline Succeeded",
                "attachments": [{
                  "color": "#00FF00",
                  "title": "Pipeline Success",
                  "title_link": "${{ github.server_url }}/${{ github.repository }}/actions/runs/${{ github.run_id }}",
                  "text": "The agentic pipeline completed successfully."
                }]
              }' 2>/dev/null
          fi

      - name: Notify Failure
        if: failure()
        run: |
          if [ -n "${{ secrets.NOTIFICATION_WEBHOOK_URL }}" ]; then
            curl -X POST "${{ secrets.NOTIFICATION_WEBHOOK_URL }}" \
              -H "Content-Type: application/json" \
              -d '{
                "text": "‚ùå Vibe Pipeline Failed",
                "attachments": [{
                  "color": "#FF0000",
                  "title": "Pipeline Failure - Check GitHub Issues",
                  "title_link": "${{ github.server_url }}/${{ github.repository }}/actions/runs/${{ github.run_id }}",
                  "text": "The agentic pipeline failed after self-healing attempts. A GitHub Issue should have been created with details."
                }]
              }' 2>/dev/null
          fi

          if [ -n "${{ secrets.LOGIC_APP_EMAIL_URL }}" ]; then
            curl -X POST "${{ secrets.LOGIC_APP_EMAIL_URL }}" \
              -H "Content-Type: application/json" \
              -d '{
                "subject": "Vibe Pipeline Failed - Manual Intervention Required",
                "body": "The pipeline failed after self-healing attempts.\n\nRun: ${{ github.server_url }}/${{ github.repository }}/actions/runs/${{ github.run_id }}\n\nCheck GitHub Issues for detailed root cause analysis.",
                "severity": "high"
              }' 2>/dev/null
          fi

  # =============================================================================
  # Deploy Dashboard to GitHub Pages
  # =============================================================================
  deploy-dashboard:
    name: Deploy Dashboard
    needs: agentic-pipeline
    runs-on: ubuntu-latest
    if: success()

    environment:
      name: github-pages
      url: ${{ steps.deployment.outputs.page_url }}

    steps:
      - name: Deploy to GitHub Pages
        id: deployment
        uses: actions/deploy-pages@v4
